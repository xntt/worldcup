import json
import os
import random
import time
import google.generativeai as genai
import feedparser # ğŸ‘ˆ æ–°å¢ï¼šç”¨äºæŠ“å– RSS
from datetime import datetime, timedelta

# --- 1. é…ç½® ---
GEMINI_KEY = os.environ.get("GEMINI_API_KEY")
if GEMINI_KEY:
    genai.configure(api_key=GEMINI_KEY)

SITES_FILE = 'sites.json'
OFFERS_FILE = 'offers.json'

# --- çœŸå®æ–°é—»æº (RSS Feeds) ---
# è¿™é‡Œæ±‡é›†äº†å…¨çƒå„å¤§ä½“è‚²æ–°é—»æº
RSS_SOURCES = [
    "https://www.espn.com/espn/rss/soccer/news", 
    "https://feeds.bbci.co.uk/sport/football/rss.xml",
    "https://www.goal.com/feeds/en/news"
]

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def fetch_real_news_from_rss():
    """ä» RSS æºæŠ“å–æœ€æ–°æ–°é—»"""
    print("ğŸ“¡ Fetching Real News from RSS...")
    raw_articles = []
    
    for url in RSS_SOURCES:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:2]: # æ¯ä¸ªæºåªå–å‰2æ¡ï¼Œé¿å…å¤ªé•¿
                raw_articles.append({
                    "title": entry.title,
                    "summary": getattr(entry, 'summary', entry.title)
                })
        except Exception as e:
            print(f"RSS Error ({url}): {e}")
            
    # æ‰“ä¹±é¡ºåºï¼Œè®©æ¯æ¬¡çœ‹èµ·æ¥ä¸ä¸€æ ·
    random.shuffle(raw_articles)
    return raw_articles[:3] # åªè¿”å›å‰3æ¡ç»™ AI æ”¹å†™

def ai_rewrite_content(domain, theme, geo, raw_news):
    """è°ƒç”¨ Gemini æ”¹å†™æ–°é—» + ç”Ÿæˆ SEO + ç”Ÿæˆèµ›äº‹é¢„æµ‹"""
    
    # æ„é€ ç»™ AI çš„ç´ æ
    news_context = json.dumps(raw_articles) if 'raw_articles' in locals() else "Global Football News"
    
    prompt = f"""
    Role: Senior Betting Editor for {domain} ({geo}).
    Task: 
    1. Rewrite these 3 news headlines/summaries to be exciting for bettors. Focus on odds and winning.
    2. Create 1 sentence SEO footer description.
    3. Generate 2 "Upcoming Matches" based on real teams mentioned in the news (or top teams). Include realistic odds.

    Input News Data: {news_context}

    Output JSON ONLY:
    {{
      "news": [
        {{"title": "...", "date": "Today", "excerpt": "..."}},
        {{"title": "...", "date": "Today", "excerpt": "..."}},
        {{"title": "...", "date": "Today", "excerpt": "..."}}
      ],
      "seo": "...",
      "matches": [
        {{"team_a": "...", "team_b": "...", "date": "Tomorrow 20:00", "stadium": "MetLife Stadium", "odds": "2.10"}},
        {{"team_a": "...", "team_b": "...", "date": "Next Day 18:00", "stadium": "Azteca", "odds": "1.85"}}
      ]
    }}
    """
    
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        return json.loads(text)
    except Exception as e:
        print(f"âŒ AI Generation Error: {e}")
        return None

# --- 3. ä¸»ç¨‹åº ---

def main():
    # è¯»å–é…ç½®
    with open(OFFERS_FILE, 'r') as f:
        all_offers = json.load(f)
    
    with open(SITES_FILE, 'r') as f:
        sites = json.load(f)

    # 1. å…ˆæŠ“å–ä¸€æ¬¡çœŸå®æ–°é—» (æ‰€æœ‰ç«™ç‚¹å…±ç”¨è¿™ä¸ªç´ æï¼Œçœæµé‡)
    raw_news = fetch_real_news_from_rss()
    
    print(f"ğŸ”„ Updating {len(sites)} sites with REAL data...")
    
    for site in sites:
        domain = site.get('hostname')
        theme = site.get('theme', 'modern')
        
        # ç®€å•åˆ¤æ–­ Geo
        if '.mx' in domain or 'mexico' in domain: geo = "Mexico"
        elif '.ca' in domain: geo = "Canada"
        else: geo = "Global"

        print(f"ğŸ‘‰ Processing: {domain} [{geo}]")

        # A. è°ƒç”¨ AI (ä¼ å…¥çœŸå®æ–°é—»ç´ æ)
        ai_data = ai_rewrite_content(domain, theme, geo, raw_news)
        
        if ai_data:
            # å¡«å…¥ AI ç”Ÿæˆçš„çœŸå®æ”¹å†™æ•°æ®
            site['news_data'] = ai_data.get('news', [])
            site['matches_data'] = ai_data.get('matches', [])
            
            if 'seo_content' not in site: site['seo_content'] = {}
            site['seo_content']['body'] = ai_data.get('seo', "")
            site['seo_content']['title'] = f"{domain} Betting Guide"
        else:
            print("âš ï¸ AI failed, skipping content update for this site.")

        # B. ç¡®ä¿ Offer å­˜åœ¨
        site['offer_ids'] = [o['id'] for o in all_offers[:3]]
        
        # C. ç¡®ä¿ Partners å­˜åœ¨ (é™æ€)
        site['partners_data'] = [
            "https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Mastercard-logo.svg/200px-Mastercard-logo.svg.png",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/PayPal.svg/200px-PayPal.svg.png",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Apple_logo_black.svg/100px-Apple_logo_black.svg.png"
        ]
        
        # D. è¡¥å…¨å¸ƒå±€
        site['layout_order'] = ["hero", "matches", "offers", "news", "partners", "seo"]

        # ä¼‘æ¯ä¸€ä¸‹
        time.sleep(3)

    # ä¿å­˜
    with open(SITES_FILE, 'w') as f:
        json.dump(sites, f, indent=2)
    print("âœ… Real News Update Complete!")

if __name__ == "__main__":
    main()
